{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_text\n",
    "from id3 import Id3Estimator\n",
    "from id3 import export_text as id3export_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# iris Features: [Sepal Length, Sepal Width, Petal Length, Petal Width]\n",
    "# iris target: {Setosa, Versicolour, Virginica}\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print(iris.target_names)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- petal width (cm) <= 0.80\n",
      "|   |--- class: 0\n",
      "|--- petal width (cm) >  0.80\n",
      "|   |--- petal width (cm) <= 1.75\n",
      "|   |   |--- petal length (cm) <= 4.95\n",
      "|   |   |   |--- petal width (cm) <= 1.65\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- petal width (cm) >  1.65\n",
      "|   |   |   |   |--- class: 2\n",
      "|   |   |--- petal length (cm) >  4.95\n",
      "|   |   |   |--- petal width (cm) <= 1.55\n",
      "|   |   |   |   |--- class: 2\n",
      "|   |   |   |--- petal width (cm) >  1.55\n",
      "|   |   |   |   |--- petal length (cm) <= 5.45\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- petal length (cm) >  5.45\n",
      "|   |   |   |   |   |--- class: 2\n",
      "|   |--- petal width (cm) >  1.75\n",
      "|   |   |--- petal length (cm) <= 4.85\n",
      "|   |   |   |--- sepal width (cm) <= 3.10\n",
      "|   |   |   |   |--- class: 2\n",
      "|   |   |   |--- sepal width (cm) >  3.10\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- petal length (cm) >  4.85\n",
      "|   |   |   |--- class: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "r = export_text(clf, feature_names=iris.feature_names)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree id3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "petal length (cm) <=2.45: 0 (50) \n",
      "petal length (cm) >2.45\n",
      "|   petal width (cm) <=1.75\n",
      "|   |   sepal length (cm) <=7.10\n",
      "|   |   |   sepal width (cm) <=2.85: 1 (27/4) \n",
      "|   |   |   sepal width (cm) >2.85: 1 (22) \n",
      "|   |   sepal length (cm) >7.10: 2 (1) \n",
      "|   petal width (cm) >1.75\n",
      "|   |   sepal length (cm) <=5.95\n",
      "|   |   |   sepal width (cm) <=3.10: 2 (6) \n",
      "|   |   |   sepal width (cm) >3.10: 1 (1) \n",
      "|   |   sepal length (cm) >5.95: 2 (39) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X, y)\n",
    "\n",
    "r = id3export_text(estimator.tree_, feature_names=iris.feature_names)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# play-tennis Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Day   Outlook Temperature Humidity    Wind PlayTennis\n",
      "0    D1     Sunny         Hot     High    Weak         No\n",
      "1    D2     Sunny         Hot     High  Strong         No\n",
      "2    D3  Overcast         Hot     High    Weak        Yes\n",
      "3    D4      Rain        Mild     High    Weak        Yes\n",
      "4    D5      Rain        Cool   Normal    Weak        Yes\n",
      "5    D6      Rain        Cool   Normal  Strong         No\n",
      "6    D7  Overcast        Cool   Normal  Strong        Yes\n",
      "7    D8     Sunny        Mild     High    Weak         No\n",
      "8    D9     Sunny        Cool   Normal    Weak        Yes\n",
      "9   D10      Rain        Mild   Normal    Weak        Yes\n",
      "10  D11     Sunny        Mild   Normal  Strong        Yes\n",
      "11  D12  Overcast        Mild     High  Strong        Yes\n",
      "12  D13  Overcast         Hot   Normal    Weak        Yes\n",
      "13  D14      Rain        Mild     High  Strong         No\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocessing data\n",
    "df = pd.read_csv('play-tennis.csv')\n",
    "\n",
    "print(df)\n",
    "le_list = []\n",
    "for col in df:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df[col])\n",
    "    df[col] = le.transform(df[col])\n",
    "    le_list.append(le)\n",
    "\n",
    "headers = list(df.columns[1:])\n",
    "feature_names = headers[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- Outlook <= 0.50\n",
      "|   |--- class: 1\n",
      "|--- Outlook >  0.50\n",
      "|   |--- Humidity <= 0.50\n",
      "|   |   |--- Outlook <= 1.50\n",
      "|   |   |   |--- Wind <= 0.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- Wind >  0.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- Outlook >  1.50\n",
      "|   |   |   |--- class: 0\n",
      "|   |--- Humidity >  0.50\n",
      "|   |   |--- Wind <= 0.50\n",
      "|   |   |   |--- Temperature <= 1.00\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- Temperature >  1.00\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- Wind >  0.50\n",
      "|   |   |   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tennis = tree.DecisionTreeClassifier()\n",
    "clf_tennis.X_encoders_ = le_list[1:-1]\n",
    "clf_tennis.y_encoders_ = le_list[-1]\n",
    "clf_tennis = clf_tennis.fit(df[feature_names], df[headers[-1]])\n",
    "\n",
    "r = export_text(clf_tennis, feature_names=feature_names)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree id3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outlook <=0.50: 1 (4) \n",
      "Outlook >0.50\n",
      "|   Humidity <=0.50\n",
      "|   |   Temperature <=1.50: 0 (2) \n",
      "|   |   Temperature >1.50\n",
      "|   |   |   Wind <=0.50: 0 (1) \n",
      "|   |   |   Wind >0.50: 0 (1/1) \n",
      "|   Humidity >0.50\n",
      "|   |   Wind <=0.50\n",
      "|   |   |   Temperature <=1.00: 0 (1) \n",
      "|   |   |   Temperature >1.00: 1 (1) \n",
      "|   |   Wind >0.50: 1 (3) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator = Id3Estimator()\n",
    "estimator.X_encoders_ = le_list[1:-1]\n",
    "estimator.y_encoders_ = le_list[-1]\n",
    "\n",
    "estimator = estimator.fit(df[feature_names], df[headers[-1]])\n",
    "\n",
    "r = id3export_text(estimator.tree_, feature_names=feature_names)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Persamaan dan Perbedaan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier (optimised version of CART algo) vs di buku\n",
    "\n",
    "|Perbedaan|DecisionTreeClassifier (CART)|ID3|\n",
    "| ------------- |-------------|-----|\n",
    "| Penentuan atribut terbaik | Gini Impurity (default) or Information gain | Highest Information gain |\n",
    "| Penanganan label dari cabang setiap nilai atribut | Apabila (depth >= max_depth) atau (n_node_samples < min_samples_split) atau (n_node_samples < 2 * min_samples_leaf) atau (weighted_n_node_samples < 2 * min_weight_leaf) or (impurity <= min_impurity_split) atau (all sample belong to 1 class) atau (split.improvement + EPSILON < min_impurity_decrease) maka node tersebut adalah leaf node (target), Jika tidak maka dilakukan split dengan attribute tertentu | all Example should belong to one class (100% pure) |\n",
    "| Penentuan label jika examples kosong di cabang tersebut | Dipilih kelas target paling banyak | Dipilih kelas target paling banyak |\n",
    "| Penanganan atribut kontinu | Pada CART ditangani, namun implementasi DecisionTreeClassifier pada sklearn tidak menangani atribut kontinu | Tidak ditangani |\n",
    "| Penanganan atribut dengan missing values | Mengabaikan missing value ketika mensplit | Mengabaikan missing value |\n",
    "| Pruning dan parameter confidence | Post-Pruned, complexity pruning | Tidak ada pruning |\n",
    "\n",
    "\n",
    "|Perbedaan|decision-tree-id3|ID3|\n",
    "| ------------- |-------------|-----|\n",
    "| Penentuan atribut terbaik | highest Information gain (optional: gain ratio) | Highest Information gain |\n",
    "| Penanganan label dari cabang setiap nilai atribut | Apabila (jumlah sampel < jumlah minimal sampel split (default = 1)) atau (depth tree >= defined max_depth) atau (entrophy_decrease < defined minimum_entropy_decrease (default = 0)) maka node tersebut adalah leaf node (target), Jika tidak maka dilakukan split dengan attribute tertentu | all Example should belong to one class (100% pure) |\n",
    "| Penentuan label jika examples kosong di cabang tersebut | Dipilih kelas target paling banyak | Dipilih kelas target paling banyak |\n",
    "| Penanganan atribut kontinu | Ditangani, float dijadikan int sebelum splitting | Tidak ditangani |\n",
    "| Penanganan atribut dengan missing values | Mengabaikan missing value ketika mensplit | Mengabaikan missing value |\n",
    "| Pruning dan parameter confidence | Post-Pruned | Tidak ada pruning |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
