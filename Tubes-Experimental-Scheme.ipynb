{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "from sklearn import neural_network\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_text\n",
    "from id3 import Id3Estimator\n",
    "from id3 import export_text as id3export_text\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# Iris\n",
    "# iris Features: [Sepal Length, Sepal Width, Petal Length, Petal Width]\n",
    "# iris target: {Setosa, Versicolour, Virginica}\n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "print(iris.target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  96.74603174603175\n",
      "Recall   :  96.74603174603175\n",
      "[[19  0  0]\n",
      " [ 0 20  1]\n",
      " [ 0  1 19]]\n",
      "Kinerja DTL dengan skema Split Train = 96.66666666666667 %\n"
     ]
    }
   ],
   "source": [
    "# DTL Skema Split Train\n",
    "# TODO: Confusion matrix\n",
    "dtl_model = tree.DecisionTreeClassifier()\n",
    "dtl_train_X, dtl_test_X, dtl_train_y, dtl_test_y = train_test_split(iris_X, iris_y, test_size=0.4, random_state=1)\n",
    "dtl_model = dtl_model.fit(dtl_train_X, dtl_train_y)\n",
    "\n",
    "y_pred = dtl_model.predict(dtl_test_X)\n",
    "\n",
    "matrix = confusion_matrix(dtl_test_y, y_pred)\n",
    "\n",
    "pred_column = []\n",
    "truth_row = []\n",
    "\n",
    "for i in range(0, len(matrix)):\n",
    "    pred_column.append(1)\n",
    "    truth_row.append(1)\n",
    "    tempSumPred = 0\n",
    "    tempSumTruth = 0\n",
    "    for j in range(0, len(matrix[i])):\n",
    "        tempSumPred += matrix[j][i]\n",
    "        tempSumTruth += matrix[i][j]\n",
    "    pred_column[i] = max(pred_column[i], tempSumPred)\n",
    "    truth_row[i] = max(truth_row[i], tempSumTruth)\n",
    "\n",
    "tempSumPred = 0\n",
    "tempSumTruth = 0\n",
    "for i in range(0, len(matrix)):\n",
    "    tempSumPred += matrix[i][i]/pred_column[i] # precision\n",
    "    tempSumTruth += matrix[i][i]/truth_row[i] # recall\n",
    "tempSumPred /= len(matrix)\n",
    "tempSumTruth /= len(matrix)\n",
    "\n",
    "print(\"Precision: \", tempSumPred*100)\n",
    "print(\"Recall   : \", tempSumTruth*100)\n",
    "\n",
    "print(matrix)\n",
    "\n",
    "# Kinerja\n",
    "print(\"Kinerja DTL dengan skema Split Train =\", dtl_model.score(dtl_test_X, dtl_test_y)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTL Skema 10-fold cross validation\n",
    "# Referensi: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  96.96969696969697\n",
      "Recall   :  96.82539682539682\n",
      "[[19  0  0]\n",
      " [ 0 19  2]\n",
      " [ 0  0 20]]\n",
      "Kinerja ANN dengan skema Split Train = 96.66666666666667 %\n"
     ]
    }
   ],
   "source": [
    "# ANN Skema Split Train\n",
    "# TODO: Confusion Matrix\n",
    "ANN_model = neural_network.MLPClassifier(hidden_layer_sizes=(3, 2), max_iter=10000, random_state=3)\n",
    "ANN_train_X, ANN_test_X, ANN_train_y, ANN_test_y = train_test_split(iris_X, iris_y, test_size=0.4, random_state=1)\n",
    "ANN_model = ANN_model.fit(ANN_train_X, ANN_train_y)\n",
    "\n",
    "y_pred = ANN_model.predict(ANN_test_X)\n",
    "\n",
    "matrix = confusion_matrix(ANN_test_y, y_pred)\n",
    "\n",
    "pred_column = []\n",
    "truth_row = []\n",
    "\n",
    "for i in range(0, len(matrix)):\n",
    "    pred_column.append(1)\n",
    "    truth_row.append(1)\n",
    "    tempSumPred = 0\n",
    "    tempSumTruth = 0\n",
    "    for j in range(0, len(matrix[i])):\n",
    "        tempSumPred += matrix[j][i]\n",
    "        tempSumTruth += matrix[i][j]\n",
    "    pred_column[i] = max(pred_column[i], tempSumPred)\n",
    "    truth_row[i] = max(truth_row[i], tempSumTruth)\n",
    "\n",
    "tempSumPred = 0\n",
    "tempSumTruth = 0\n",
    "for i in range(0, len(matrix)):\n",
    "    tempSumPred += matrix[i][i]/pred_column[i] # precision\n",
    "    tempSumTruth += matrix[i][i]/truth_row[i] # recall\n",
    "tempSumPred /= len(matrix)\n",
    "tempSumTruth /= len(matrix)\n",
    "\n",
    "print(\"Precision: \", tempSumPred*100)\n",
    "print(\"Recall   : \", tempSumTruth*100)\n",
    "\n",
    "print(matrix)\n",
    "print(\"Kinerja ANN dengan skema Split Train =\", ANN_model.score(ANN_test_X, ANN_test_y)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Skema 10-fold cross validation\n",
    "# Referensi: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Export DTL Model\n",
    "print(dtl_model)\n",
    "filename = 'finalized_model.sav'\n",
    "joblib.dump(dtl_model, filename)\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(dtl_test_X, dtl_test_y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(3, 2), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=10000,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=3, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Export ANN Model\n",
    "print(ANN_model)\n",
    "filename = 'finalized_mlp_model.sav'\n",
    "joblib.dump(ANN_model, filename)\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(ANN_test_X, ANN_test_y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
